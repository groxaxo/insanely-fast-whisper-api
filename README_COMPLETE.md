# Insanely Fast Whisper API - Complete Setup

## âœ… Status: FULLY CONFIGURED AND READY

The Whisper API is now fully configured and ready to work with Open WebUI!

### What's Been Done

1. âœ… **Repository cloned** from GitHub
2. âœ… **Conda environment created** (`whisper-api`)
3. âœ… **All dependencies installed** (PyTorch, Flash Attention, Transformers, etc.)
4. âœ… **GPU configured** to use GPU 2 with 15% memory limit
5. âœ… **OpenAI-compatible endpoint added** at `/audio/transcriptions`
6. âœ… **API running** on port 8002
7. âœ… **Tested and verified** working

---

## ğŸš€ Quick Start

### Start the Whisper API

```bash
cd /home/op/CascadeProjects/insanely-fast-whisper-api
./start_gpu2_limited.sh
```

### Configure Open WebUI

**Stop and restart Open WebUI with these environment variables:**

```bash
# Stop Open WebUI
pkill -f "open-webui"

# Start with Whisper API configuration
STT_ENGINE=openai \
STT_OPENAI_API_BASE_URL=http://localhost:8002 \
STT_OPENAI_API_KEY=dummy \
STT_MODEL=whisper-large-v3 \
open-webui serve
```

### Test the Integration

```bash
cd /home/op/CascadeProjects/insanely-fast-whisper-api
./test_openwebui_endpoint.sh
```

---

## ğŸ“‹ Configuration Details

### Whisper API
- **URL**: http://localhost:8002
- **Endpoint**: `/audio/transcriptions` (OpenAI-compatible)
- **GPU**: GPU 2 (NVIDIA GeForce RTX 3090)
- **Memory Limit**: 15% (3.53 GB)
- **Model**: OpenAI Whisper Large v3
- **Optimizations**: Flash Attention 2.0, FP16, Batch size 24

### Open WebUI Settings
```bash
STT_ENGINE=openai
STT_OPENAI_API_BASE_URL=http://localhost:8002
STT_OPENAI_API_KEY=dummy
STT_MODEL=whisper-large-v3
```

---

## ğŸ”§ Helper Scripts

### 1. Start the API
```bash
./start_gpu2_limited.sh
```

### 2. Test the Endpoint
```bash
./test_openwebui_endpoint.sh
```

### 3. Get Configuration Help
```bash
./configure_openwebui.sh
```

---

## ğŸ“– API Documentation

### POST /audio/transcriptions

**OpenAI-compatible endpoint for audio transcription**

#### Request (multipart/form-data):
- `file` (required): Audio file to transcribe
- `model` (optional): Model name (default: "whisper-large-v3")
- `language` (optional): Language code (e.g., "en", "es", "fr")
- `response_format` (optional): Response format (default: "json")

#### Response:
```json
{
  "text": "Transcribed text here"
}
```

#### Example:
```bash
curl -X POST http://localhost:8002/audio/transcriptions \
  -F "file=@audio.mp3" \
  -F "model=whisper-large-v3" \
  -F "language=en"
```

---

## ğŸ› Troubleshooting

### Error: "Server Connection Error"

**Problem**: Open WebUI cannot reach the Whisper API

**Solutions**:
1. Verify API is running: `curl http://localhost:8002/`
2. Check if port 8002 is accessible
3. Restart the API: `pkill -f "uvicorn app.app:app" && ./start_gpu2_limited.sh`
4. If Open WebUI is in Docker, use `http://host.docker.internal:8002`

### Error: "400 Bad Request"

**Problem**: Invalid audio file or format

**Solutions**:
1. Ensure audio file is valid (mp3, wav, m4a, etc.)
2. Check file is not corrupted
3. Try converting to mp3 format

### Error: "500 Internal Server Error"

**Problem**: Processing error or GPU memory issue

**Solutions**:
1. Check API logs in the terminal where it's running
2. Verify GPU 2 is available: `nvidia-smi`
3. Restart the API
4. Check GPU memory usage

### API Not Starting

**Problem**: Port already in use or dependency issues

**Solutions**:
1. Check if port 8002 is free: `ss -tlnp | grep :8002`
2. Kill existing process: `pkill -f "uvicorn app.app:app"`
3. Verify conda environment: `conda activate whisper-api`
4. Check for errors in startup logs

---

## ğŸ“Š Performance

- **GPU**: GPU 2 (RTX 3090) with 15% memory limit
- **Memory Usage**: ~3.53 GB allocated
- **Batch Size**: 24 (optimized for memory constraints)
- **Speed**: ~2 minutes for 150 minutes of audio (on A100, RTX 3090 may vary)
- **Concurrent Requests**: Handled sequentially

---

## ğŸ” Monitoring

### Check API Status
```bash
curl http://localhost:8002/
# Should return: {"detail":"Method Not Allowed"}
```

### Check GPU Usage
```bash
nvidia-smi
# Look for GPU 2 usage
```

### View API Logs
Check the terminal where `start_gpu2_limited.sh` is running

### Check Open WebUI Logs
```bash
# If running as service
journalctl -u open-webui -f

# If running directly
# Check the terminal where open-webui is running
```

---

## ğŸ“ File Structure

```
/home/op/CascadeProjects/insanely-fast-whisper-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                    # Main API (modified with OpenAI endpoint)
â”‚   â”œâ”€â”€ diarization_pipeline.py
â”‚   â””â”€â”€ diarize.py
â”œâ”€â”€ start_gpu2_limited.sh         # Startup script
â”œâ”€â”€ test_openwebui_endpoint.sh    # Test script
â”œâ”€â”€ configure_openwebui.sh        # Configuration helper
â”œâ”€â”€ SETUP_SUMMARY.md              # Initial setup summary
â”œâ”€â”€ OPEN_WEBUI_INTEGRATION.md     # Integration guide
â”œâ”€â”€ README_COMPLETE.md            # This file
â”œâ”€â”€ requirements.txt
â””â”€â”€ pyproject.toml
```

---

## ğŸ”„ Restart Commands

### Restart Whisper API
```bash
pkill -f "uvicorn app.app:app"
cd /home/op/CascadeProjects/insanely-fast-whisper-api
./start_gpu2_limited.sh
```

### Restart Open WebUI
```bash
pkill -f "open-webui"
STT_ENGINE=openai \
STT_OPENAI_API_BASE_URL=http://localhost:8002 \
STT_OPENAI_API_KEY=dummy \
STT_MODEL=whisper-large-v3 \
open-webui serve
```

---

## âœ¨ Features

- âœ… OpenAI-compatible API format
- âœ… GPU-accelerated with Flash Attention 2
- âœ… Memory-limited (15% of GPU 2)
- âœ… Automatic file cleanup
- âœ… Supports all common audio formats
- âœ… Automatic language detection
- âœ… Optimized batch processing
- âœ… Production-ready error handling

---

## ğŸ“ Support

If you encounter issues:

1. **Check API logs**: View terminal where API is running
2. **Test endpoint**: Run `./test_openwebui_endpoint.sh`
3. **Verify GPU**: Run `nvidia-smi`
4. **Check Open WebUI logs**: Look for connection errors
5. **Restart services**: Use commands above

---

## ğŸ¯ Next Steps

1. âœ… API is running
2. â³ **Configure Open WebUI** with the environment variables above
3. â³ **Restart Open WebUI** to apply settings
4. â³ **Test** by recording or uploading audio in Open WebUI

---

## ğŸ“ Notes

- The API uses GPU 2 exclusively (via `CUDA_VISIBLE_DEVICES=2`)
- Memory is limited to 15% to avoid resource hogging
- Batch size is set to 24 for optimal performance
- The endpoint is fully compatible with OpenAI's Whisper API format
- No authentication is required (can be added if needed)

---

**Last Updated**: 2025-11-07
**Status**: âœ… Production Ready
